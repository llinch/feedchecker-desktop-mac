from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse, StreamingResponse
import logging
import tempfile
import os
import json
import asyncio
import threading
from pathlib import Path
from typing import AsyncGenerator, Dict, Any
from uuid import uuid4
from datetime import datetime

from app.feed_checker import FeedChecker, ProblemType
from app.delta_feed_checker import DeltaFeedChecker
from app.excel_export import create_excel_report
from app.exceptions import FeedDownloadError, FeedValidationError

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–æ–≥–æ–≤
# –í Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º /app/backend.log, –ª–æ–∫–∞–ª—å–Ω–æ - –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
if os.path.exists('/app'):
    # –ú—ã –≤ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
    log_file_path = Path('/app/backend.log')
else:
    # –õ–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ - –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
    log_file_path = Path(__file__).parent.parent.parent.parent / 'backend.log'

# –°–æ–∑–¥–∞–µ–º handlers –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
# –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è Windows –∫–æ–Ω—Å–æ–ª–∏
import sys
if sys.platform == 'win32':
    import io
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º UTF-8 –¥–ª—è stdout/stderr –≤ Windows
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    if hasattr(sys.stderr, 'reconfigure'):
        sys.stderr.reconfigure(encoding='utf-8', errors='replace')

handlers = [logging.StreamHandler()]  # –í—Å–µ–≥–¥–∞ –ª–æ–≥–∏—Ä—É–µ–º –≤ –∫–æ–Ω—Å–æ–ª—å (stdout/stderr)

# –ü—Ä–æ–±—É–µ–º –¥–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª–æ–≤—ã–π handler, –Ω–æ –Ω–µ –ø–∞–¥–∞–µ–º –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å
try:
    log_file_path.parent.mkdir(parents=True, exist_ok=True)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –Ω–∞ –∑–∞–ø–∏—Å—å
    test_file = log_file_path.parent / '.write_test'
    try:
        test_file.write_text('test')
        test_file.unlink()
        handlers.append(logging.FileHandler(log_file_path, encoding='utf-8', mode='a'))
        print(f"Log file will be written to: {log_file_path}")
    except Exception:
        print(f"Cannot write to log file directory: {log_file_path.parent}, using console only")
except Exception as e:
    print(f"Could not setup log file: {e}, using console only")

logging.basicConfig(
    level=logging.INFO,
    format=log_format,
    handlers=handlers,
    force=True  # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
)
logger = logging.getLogger(__name__)

# –¢–µ—Å—Ç–æ–≤–∞—è –∑–∞–ø–∏—Å—å –≤ –ª–æ–≥
logger.info("="*80)
logger.info("Backend application starting...")
logger.info(f"Log file path: {log_file_path}")
logger.info(f"Working directory: {os.getcwd()}")
logger.info(f"Python path: {os.sys.path[:3]}")
logger.info("="*80)

app = FastAPI(
    title="FeedChecker API",
    description="API –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ XML/YML —Ñ–∏–¥–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤",
    version="1.0.0",
)

# CORS middleware
cors_origins_env = os.getenv("CORS_ORIGINS", "*")
if cors_origins_env == "*":
    cors_origins = ["*"]
    logger.info(f"CORS origins configured: * (all origins allowed)")
else:
    cors_origins = [origin.strip() for origin in cors_origins_env.split(",")]
    logger.info(f"CORS origins configured: {cors_origins}")

app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Middleware –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
@app.middleware("http")
async def log_requests(request, call_next):
    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ health checks - –æ–Ω–∏ —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç—ã–µ –∏ –Ω–µ –Ω–µ—Å—É—Ç –ø–æ–ª–µ–∑–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    is_health_check = request.url.path == "/health"
    
    if not is_health_check:
        # –õ–æ–≥–∏—Ä—É–µ–º –≤ —Ñ–∞–π–ª –∏ –∫–æ–Ω—Å–æ–ª—å
        log_msg = f"üì• Incoming request: {request.method} {request.url.path}"
        logger.info(log_msg)
        
        if request.url.query:
            log_msg = f"   Query params: {request.url.query}"
            logger.info(log_msg)
    
    response = await call_next(request)
    
    if not is_health_check:
        log_msg = f"üì§ Response: {response.status_code} for {request.method} {request.url.path}"
        logger.info(log_msg)
    
    return response

# In-memory job storage (–≤ production –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Redis)
jobs: Dict[str, Dict[str, Any]] = {}
jobs_lock = threading.Lock()

async def process_feed_background(job_id: str, site_id: int, feed_url: str = None, file_content: bytes = None, feed_type: str = "xml", delimiter: str = ";"):
    """
    –§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∏–¥–∞
    """
    try:
        with jobs_lock:
            jobs[job_id]["status"] = "processing"
            jobs[job_id]["progress"] = 10
            jobs[job_id]["message"] = "–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∏–¥–∞..."

        logger.info(f"üîÑ Starting background job {job_id} for site_id {site_id}, feed_type: {feed_type}")

        feed_type_lower = feed_type.lower() if feed_type else "xml"
        
        # –°–æ–∑–¥–∞–µ–º checker –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∏–¥–∞
        if feed_type_lower == "delta":
            if feed_url:
                checker = DeltaFeedChecker(
                    site_id=site_id,
                    site_url=feed_url,
                    delimiter=delimiter
                )
            else:
                checker = DeltaFeedChecker(
                    site_id=site_id,
                    file_content=file_content,
                    delimiter=delimiter
                )
        else:
            if feed_url:
                checker = FeedChecker(site_id=site_id, site_url=feed_url)
            else:
                checker = FeedChecker(site_id=site_id, file_content=file_content)

        with jobs_lock:
            jobs[job_id]["progress"] = 30
            jobs[job_id]["message"] = "–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∏–¥–∞..."

        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ thread pool —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å event loop
        result = await asyncio.to_thread(checker.run_full_check)

        with jobs_lock:
            jobs[job_id]["status"] = "completed"
            jobs[job_id]["progress"] = 100
            jobs[job_id]["message"] = "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞"
            jobs[job_id]["result"] = result
            jobs[job_id]["result"]["site_id"] = site_id
            jobs[job_id]["completed_at"] = datetime.now().isoformat()

        logger.info(f"‚úÖ Job {job_id} completed successfully")

    except FeedDownloadError as e:
        logger.error(f"‚ùå Job {job_id} failed with download error: {e.message}")
        with jobs_lock:
            jobs[job_id]["status"] = "failed"
            jobs[job_id]["error"] = {
                "error_type": "download_error",
                "error_code": e.error_code,
                "message": e.message,
                "url": e.url,
                "http_status": e.status_code,
                "details": e.details
            }
            jobs[job_id]["failed_at"] = datetime.now().isoformat()

    except FeedValidationError as e:
        logger.warning(f"‚ö†Ô∏è Job {job_id} completed with validation error: {e.message}")
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ validation_results - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å, –∞ –Ω–µ —Å–ø–∏—Å–æ–∫
        validation_results = e.validation_results if isinstance(e.validation_results, dict) else {}
        
        with jobs_lock:
            jobs[job_id]["status"] = "completed_with_errors"
            jobs[job_id]["progress"] = 100
            jobs[job_id]["message"] = "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"
            jobs[job_id]["result"] = {
                "site_id": site_id,
                "validation_error": True,
                "message": e.message,
                **validation_results
            }
            jobs[job_id]["completed_at"] = datetime.now().isoformat()

    except Exception as e:
        logger.error(f"üí• Job {job_id} failed with unexpected error: {str(e)}", exc_info=True)
        with jobs_lock:
            jobs[job_id]["status"] = "failed"
            jobs[job_id]["error"] = {
                "error_type": "internal_error",
                "message": f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: {str(e)}",
                "error_class": type(e).__name__
            }
            jobs[job_id]["failed_at"] = datetime.now().isoformat()

@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π endpoint"""
    return {
        "message": "FeedChecker API",
        "version": "1.0.0",
        "docs": "/docs",
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥—É–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è
        import app.feed_checker
        import app.delta_feed_checker
        return {
            "status": "ok",
            "timestamp": datetime.now().isoformat(),
            "version": "1.0.0"
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=503, detail=f"Service unhealthy: {str(e)}")

@app.get("/api/logs")
async def get_logs(lines: int = 100):
    """
    –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å—Ç—Ä–æ–∫ –ª–æ–≥–æ–≤
    
    Args:
        lines: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Ç—Ä–æ–∫ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 100, –º–∞–∫—Å–∏–º—É–º 1000)
    """
    try:
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º 1000 —Å—Ç—Ä–æ–∫
        lines = min(max(1, lines), 1000)
        
        if not log_file_path.exists():
            return {
                "error": "Log file not found",
                "log_file_path": str(log_file_path),
                "exists": False,
                "message": "–§–∞–π–ª –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω. –í–æ–∑–º–æ–∂–Ω–æ, –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ñ–∞–π–ª –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ."
            }
        
        # –ß–∏—Ç–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å—Ç—Ä–æ–∫
        with open(log_file_path, 'r', encoding='utf-8', errors='ignore') as f:
            all_lines = f.readlines()
            last_lines = all_lines[-lines:] if len(all_lines) > lines else all_lines
        
        return {
            "log_file_path": str(log_file_path),
            "total_lines": len(all_lines),
            "returned_lines": len(last_lines),
            "lines": last_lines,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Error reading logs: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –ª–æ–≥–æ–≤: {str(e)}")

@app.get("/api/logs/download")
async def download_logs():
    """
    –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª –ª–æ–≥–æ–≤
    """
    try:
        if not log_file_path.exists():
            raise HTTPException(
                status_code=404,
                detail=f"–§–∞–π–ª –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {log_file_path}"
            )
        
        return FileResponse(
            path=str(log_file_path),
            filename=f"backend_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
            media_type="text/plain"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error downloading logs: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –ª–æ–≥–æ–≤: {str(e)}")

@app.get("/api/logs/info")
async def get_logs_info():
    """
    –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ –ª–æ–≥–æ–≤
    """
    try:
        if not log_file_path.exists():
            return {
                "exists": False,
                "log_file_path": str(log_file_path),
                "message": "–§–∞–π–ª –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω"
            }
        
        stat = log_file_path.stat()
        with open(log_file_path, 'r', encoding='utf-8', errors='ignore') as f:
            line_count = sum(1 for _ in f)
        
        return {
            "exists": True,
            "log_file_path": str(log_file_path),
            "size_bytes": stat.st_size,
            "size_mb": round(stat.st_size / 1024 / 1024, 2),
            "line_count": line_count,
            "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
            "created": datetime.fromtimestamp(stat.st_ctime).isoformat(),
        }
    except Exception as e:
        logger.error(f"Error getting logs info: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ª–æ–≥–∞—Ö: {str(e)}")

@app.post("/api/check-feed-async")
async def check_feed_async(
    site_id: int = Form(...),
    feed_url: str = Form(None),
    feed_file: UploadFile = File(None),
    feed_type: str = Form("xml"),
    delimiter: str = Form(";"),
):
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–¥–∞ - –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç job_id –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    """
    try:
        if not feed_url and not feed_file:
            raise HTTPException(
                status_code=400,
                detail="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ª–∏–±–æ URL —Ñ–∏–¥–∞, –ª–∏–±–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª",
            )

        if feed_url and feed_file:
            raise HTTPException(
                status_code=400,
                detail="–£–∫–∞–∂–∏—Ç–µ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∏—Å—Ç–æ—á–Ω–∏–∫: URL –∏–ª–∏ —Ñ–∞–π–ª",
            )

        # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –∑–∞–¥–∞—á–∏
        job_id = str(uuid4())

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–¥–∞—á—É
        with jobs_lock:
            jobs[job_id] = {
                "job_id": job_id,
                "site_id": site_id,
                "status": "pending",
                "progress": 0,
                "message": "–ó–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞, –æ–∂–∏–¥–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏",
                "created_at": datetime.now().isoformat(),
                "result": None,
                "error": None
            }

        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        file_content = None
        if feed_file:
            file_content = await feed_file.read()
            logger.info(f"üìÅ Created async job {job_id} for file: {feed_file.filename} ({len(file_content)} bytes)")
        else:
            logger.info(f"üîó Created async job {job_id} for URL: {feed_url}")

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
        asyncio.create_task(
            process_feed_background(job_id, site_id, feed_url, file_content, feed_type, delimiter)
        )

        return JSONResponse({
            "job_id": job_id,
            "status": "pending",
            "message": "–ó–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞ –∏ –∑–∞–ø—É—â–µ–Ω–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ",
            "poll_url": f"/api/job/{job_id}",
            "created_at": jobs[job_id]["created_at"]
        })

    except Exception as e:
        logger.error(f"Error creating async job: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/job/{job_id}")
async def get_job_status(job_id: str, include_result: bool = False):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏

    –°—Ç–∞—Ç—É—Å—ã:
    - pending: –∑–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞, –æ–∂–∏–¥–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
    - processing: –∑–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è
    - completed: –∑–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ
    - completed_with_errors: –∑–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    - failed: –∑–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π

    –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –≤–∫–ª—é—á–∞–µ—Ç—Å—è (–¥–ª—è polling).
    –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ include_result=true –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
    """
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(
                status_code=404,
                detail=f"Job {job_id} not found"
            )

        job = jobs[job_id].copy()

        # –ù–µ –≤–∫–ª—é—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ polling –æ—Ç–≤–µ—Ç—ã –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç—Ä–∞—Ñ–∏–∫–∞
        if not include_result and "result" in job:
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
            job["has_result"] = True
            job["result"] = None

    return JSONResponse(job)

@app.delete("/api/job/{job_id}")
async def delete_job(job_id: str):
    """
    –£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –∏–∑ –ø–∞–º—è—Ç–∏ (–æ—á–∏—Å—Ç–∫–∞)
    """
    with jobs_lock:
        if job_id not in jobs:
            raise HTTPException(
                status_code=404,
                detail=f"Job {job_id} not found"
            )

        del jobs[job_id]

    return JSONResponse({"message": f"Job {job_id} deleted"})

@app.get("/api/jobs")
async def list_jobs():
    """
    –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–¥–∞—á (–¥–ª—è –¥–µ–±–∞–≥–≥–∏–Ω–≥–∞)
    """
    with jobs_lock:
        jobs_list = [
            {
                "job_id": job_id,
                "site_id": job["site_id"],
                "status": job["status"],
                "progress": job["progress"],
                "created_at": job["created_at"]
            }
            for job_id, job in jobs.items()
        ]

    return JSONResponse({
        "total": len(jobs_list),
        "jobs": jobs_list
    })

@app.post("/api/check-feed")
async def check_feed(
    site_id: int = Form(...),
    feed_url: str = Form(None),
    feed_file: UploadFile = File(None),
    feed_type: str = Form("xml"),  # "xml" –∏–ª–∏ "delta"
    delimiter: str = Form(";"),  # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–æ–≤
):
    logger.info(f"üîµ Received check-feed request: site_id={site_id}, feed_type={feed_type}, feed_url={feed_url}, has_file={feed_file is not None}")
    """
    –û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∏–¥–∞
    
    Parameters:
    - site_id: ID —Å–∞–π—Ç–∞
    - feed_url: URL —Ñ–∏–¥–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    - feed_file: –§–∞–π–ª —Ñ–∏–¥–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    - feed_type: –¢–∏–ø —Ñ–∏–¥–∞ - "xml" (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) –∏–ª–∏ "delta"
    - delimiter: –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ";")
    
    –î–æ–ª–∂–µ–Ω –±—ã—Ç—å —É–∫–∞–∑–∞–Ω –ª–∏–±–æ feed_url, –ª–∏–±–æ feed_file
    """
    try:
        if not feed_url and not feed_file:
            raise HTTPException(
                status_code=400,
                detail="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ª–∏–±–æ URL —Ñ–∏–¥–∞, –ª–∏–±–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª",
            )
        
        if feed_url and feed_file:
            raise HTTPException(
                status_code=400,
                detail="–£–∫–∞–∂–∏—Ç–µ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∏—Å—Ç–æ—á–Ω–∏–∫: URL –∏–ª–∏ —Ñ–∞–π–ª",
            )
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∏–¥–∞
        feed_type_lower = feed_type.lower() if feed_type else "xml"
        
        if feed_type_lower == "delta":
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞
            if feed_url:
                logger.info(f"üîç Checking delta feed from URL: {feed_url} for site_id: {site_id}")
                checker = DeltaFeedChecker(
                    site_id=site_id,
                    site_url=feed_url,
                    delimiter=delimiter
                )
            else:
                logger.info(f"üìÅ Checking delta feed from file: {feed_file.filename} for site_id: {site_id}")
                file_content = await feed_file.read()
                checker = DeltaFeedChecker(
                    site_id=site_id,
                    file_content=file_content,
                    delimiter=delimiter,
                    filename=feed_file.filename
                )
            
            # –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞
            logger.info(f"‚öôÔ∏è Running delta feed check for site_id: {site_id}")
            result = checker.run_full_check()
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∏–ø —Ñ–∏–¥–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result["feed_type"] = "delta"
            result["site_id"] = site_id
            
            logger.info(f"‚úÖ Delta feed check completed successfully for site_id: {site_id}")
            return JSONResponse(content=result)
        else:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ã—á–Ω–æ–≥–æ XML/YML —Ñ–∏–¥–∞
            if feed_url:
                logger.info(f"üîç Checking XML feed from URL: {feed_url} for site_id: {site_id}")
                logger.info(f"üìã URL details: scheme={feed_url.split('://')[0] if '://' in feed_url else 'unknown'}")
                checker = FeedChecker(site_id=site_id, site_url=feed_url)
            else:
                logger.info(f"üìÅ Checking feed from file: {feed_file.filename} for site_id: {site_id}")
                file_content = await feed_file.read()
                checker = FeedChecker(site_id=site_id, file_content=file_content)
            
            # –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
            logger.info(f"‚öôÔ∏è Running full feed check for site_id: {site_id}")
            result = checker.run_full_check()
            
            # –î–æ–±–∞–≤–ª—è–µ–º site_id –∏ —Ç–∏–ø —Ñ–∏–¥–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result["site_id"] = site_id
            result["feed_type"] = "xml"
            
            # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π
            logger.info(f"‚úÖ Feed check completed successfully for site_id: {site_id}")
            logger.info(f"üìä Result keys: {list(result.keys())}")
            logger.info(f"üå≥ Has category_tree: {'category_tree' in result}")
            logger.info(f"üìà Has params_stats: {'params_stats' in result}")
            logger.info(f"üè∑Ô∏è Has attributes_analysis: {'attributes_analysis' in result}")
            
            return JSONResponse(content=result)
    
    except FeedDownloadError as e:
        # –û–®–ò–ë–ö–ê –ó–ê–ì–†–£–ó–ö–ò - —Ñ–∏–¥ –Ω–µ –±—ã–ª –ø–æ–ª—É—á–µ–Ω
        logger.error(f"‚ùå DOWNLOAD ERROR for site_id {site_id}: {e.error_code} - {e.message}")
        logger.error(f"   URL: {e.url}")
        logger.error(f"   Status code: {e.status_code}")
        logger.error(f"   Details: {e.details}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ –∑–∞–≥—Ä—É–∑–∫–∏
        error_dict = e.to_dict()
        error_dict["timestamp"] = str(Path(__file__).stat().st_mtime)
        error_dict["help"] = "–≠—Ç–æ –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∏–¥–∞. –§–∏–¥ –Ω–µ –±—ã–ª –ø–æ–ª—É—á–µ–Ω —Å —Å–µ—Ä–≤–µ—Ä–∞."
        
        raise HTTPException(
            status_code=400,
            detail=error_dict
        )
    
    except FeedValidationError as e:
        # –û–®–ò–ë–ö–ê –í–ê–õ–ò–î–ê–¶–ò–ò - —Ñ–∏–¥ –ø–æ–ª—É—á–µ–Ω, –Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫–∏
        # –≠—Ç–æ –ù–ï –∫—Ä–∏—Ç–∏—á–Ω–æ - –º—ã –º–æ–∂–µ–º –ø–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        logger.warning(f"‚ö†Ô∏è VALIDATION ERROR for site_id {site_id}: {e.message}")
        logger.warning(f"   Validation results: {e.validation_results}")
        
        # –î–ª—è –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ—à–∏–±–∫—É
        if feed_type_lower == "delta":
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ validation_results - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å, –∞ –Ω–µ —Å–ø–∏—Å–æ–∫
            validation_results = e.validation_results if isinstance(e.validation_results, dict) else {}
            
            return JSONResponse(content={
                "site_id": site_id,
                "feed_type": "delta",
                "validation_error": True,
                "message": e.message,
                "parsing": {
                    "total_rows": 0,
                    "has_headers": False,
                    "headers": None,
                    "error": e.message,
                    "error_details": validation_results
                },
                "summary": {
                    "total_rows": 0,
                    "available_count": 0,
                    "unavailable_count": 0,
                    "unique_ids_count": 0
                },
                "problems": {
                    "missing_id": 0,
                    "missing_price": 0,
                    "invalid_price": 0,
                    "missing_available": 0,
                    "duplicate_ids": 0
                },
                "optional_fields": {
                    "rows_with_oldprice": 0,
                    "rows_with_region": 0,
                    "rows_with_attributes": 0,
                    "attribute_names": []
                },
                "duplicate_ids_details": [],
                **validation_results
            })
        else:
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ validation_results - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å, –∞ –Ω–µ —Å–ø–∏—Å–æ–∫
            validation_results = e.validation_results if isinstance(e.validation_results, dict) else {}
            
            return JSONResponse(content={
                "site_id": site_id,
                "validation_error": True,
                "message": e.message,
                **validation_results
            })
        
    except Exception as e:
        # –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞
        logger.error(f"üí• UNEXPECTED ERROR for site_id {site_id}: {type(e).__name__}")
        logger.error(f"   Message: {str(e)}", exc_info=True)
        
        raise HTTPException(
            status_code=500,
            detail={
                "error_type": "INTERNAL_ERROR",
                "message": f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}",
                "error_class": type(e).__name__,
                "help": "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞–º —Å –ª–æ–≥–∞–º–∏"
            }
        )

@app.get("/api/check-feed-stream")
async def check_feed_stream(
    site_id: int,
    feed_url: str,
):
    """
    Streaming endpoint –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∏–¥–∞ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º –∑–∞–≥—Ä—É–∑–∫–∏
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Server-Sent Events (SSE)
    """
    
    async def event_generator() -> AsyncGenerator[str, None]:
        try:
            logger.info(f"üîÑ Starting stream check for URL: {feed_url}, site_id: {site_id}")
            
            # Callback –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Å thread-safe –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º
            progress_data = {"loaded": 0, "total": 0}
            progress_lock = threading.Lock()
            
            def progress_callback(loaded: int, total: int):
                with progress_lock:
                    progress_data["loaded"] = loaded
                    progress_data["total"] = total
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ
            yield f"data: {json.dumps({'type': 'start', 'message': '–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∏–¥–∞...'})}\n\n"
            await asyncio.sleep(0.05)  # –ë—ã—Å—Ç—Ä–µ–µ –Ω–∞—á–∏–Ω–∞–µ–º
            
            # –°–æ–∑–¥–∞–µ–º checker —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–∫–æ–ª–±—ç–∫–æ–º
            checker = FeedChecker(
                site_id=site_id, 
                site_url=feed_url,
                progress_callback=progress_callback
            )
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –æ –Ω–∞—á–∞–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
            yield f"data: {json.dumps({'type': 'downloading', 'message': '–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∏–¥–∞...'})}\n\n"
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            result = None
            error = None
            
            async def run_check():
                nonlocal result, error
                try:
                    logger.info(f"üîÑ Starting feed check in thread pool for URL: {feed_url}")
                    import concurrent.futures
                    loop = asyncio.get_event_loop()
                    with concurrent.futures.ThreadPoolExecutor() as pool:
                        result = await loop.run_in_executor(pool, checker.run_full_check)
                    logger.info(f"‚úÖ Feed check completed successfully")
                except Exception as e:
                    logger.error(f"‚ùå Error in run_check: {str(e)}", exc_info=True)
                    error = e
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É
            check_task = asyncio.create_task(run_check())
            
            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–∫–∞ –∏–¥–µ—Ç –∑–∞–≥—Ä—É–∑–∫–∞
            last_loaded = 0
            keepalive_counter = 0
            iteration = 0
            while not check_task.done():
                await asyncio.sleep(0.2)  # 5 –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –≤ —Å–µ–∫—É–Ω–¥—É –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
                keepalive_counter += 1
                iteration += 1
                
                # –ß–∏—Ç–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å thread-safe
                with progress_lock:
                    current_loaded = progress_data["loaded"]
                    current_total = progress_data["total"]
                
                # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 10 –∏—Ç–µ—Ä–∞—Ü–∏–π (–∫–∞–∂–¥—ã–µ 2 —Å–µ–∫—É–Ω–¥—ã)
                if iteration % 10 == 0:
                    logger.info(f"üìä Progress check #{iteration}: loaded={current_loaded}, total={current_total}, task_done={check_task.done()}")
                
                if current_total > 0 and current_loaded != last_loaded:
                    # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º 0-100%
                    percentage = int((current_loaded / current_total) * 100)
                    percentage = max(0, min(percentage, 100))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 0-100
                    
                    logger.info(f"üì§ Sending progress: {current_loaded}/{current_total} ({percentage}%)")
                    yield f"data: {json.dumps({'type': 'progress', 'loaded': current_loaded, 'total': current_total, 'percentage': percentage})}\n\n"
                    last_loaded = current_loaded
                    keepalive_counter = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö
                
                # Keep-alive –ø–∏–Ω–≥ –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥ (25 –∏—Ç–µ—Ä–∞—Ü–∏–π –ø–æ 0.2—Å)
                # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —Ç–∞–π–º–∞—É—Ç –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö —Ö–æ—Å—Ç–∏–Ω–≥–∞—Ö (Render, Railway –∏ —Ç.–¥.)
                elif keepalive_counter >= 25:
                    logger.info("üíì Sending keepalive ping")
                    yield ": keepalive\n\n"  # SSE –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π, –±—Ä–∞—É–∑–µ—Ä –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç
                    keepalive_counter = 0
            
            # –î–æ–∂–∏–¥–∞–µ–º—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            await check_task
            
            if error:
                raise error
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
            yield f"data: {json.dumps({'type': 'processing', 'message': '–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...'})}\n\n"
            await asyncio.sleep(0.1)  # –ë—ã—Å—Ç—Ä–µ–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result["site_id"] = site_id
            
            # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π
            logger.info(f"üìä Stream result keys: {list(result.keys())}")
            logger.info(f"üå≥ Has category_tree: {'category_tree' in result}")
            logger.info(f"üìà Has params_stats: {'params_stats' in result}")
            logger.info(f"üè∑Ô∏è Has attributes_analysis: {'attributes_analysis' in result}")
            
            yield f"data: {json.dumps({'type': 'complete', 'result': result})}\n\n"
            
        except FeedDownloadError as e:
            logger.error(f"‚ùå DOWNLOAD ERROR: {e.message}")
            error_data = {
                'type': 'error',
                'error_type': 'download_error',
                'error_code': e.error_code,
                'message': e.message,
                'url': e.url,
                'http_status': e.status_code,
                'details': e.details,
                'human_readable': True,
            }
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            logger.error(f"üí• STREAM ERROR: {str(e)}", exc_info=True)
            error_data = {
                'type': 'error',
                'error_type': 'unknown',
                'message': str(e)
            }
            yield f"data: {json.dumps(error_data)}\n\n"
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # Disable nginx buffering
        }
    )

@app.post("/api/check-syntax")
async def check_syntax(
    site_id: int = Form(...),
    feed_url: str = Form(None),
    feed_file: UploadFile = File(None),
):
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–ª—å–∫–æ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ XML
    """
    try:
        if not feed_url and not feed_file:
            raise HTTPException(
                status_code=400,
                detail="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ª–∏–±–æ URL —Ñ–∏–¥–∞, –ª–∏–±–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª",
            )
        
        if feed_url:
            checker = FeedChecker(site_id=site_id, site_url=feed_url)
        else:
            file_content = await feed_file.read()
            checker = FeedChecker(site_id=site_id, file_content=file_content)
        
        result = checker.check_xml_syntax()
        return JSONResponse(content=result)
        
    except Exception as e:
        logger.error(f"Error checking syntax: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/get-problematic-offers")
async def get_problematic_offers(
    site_id: int = Form(...),
    feed_url: str = Form(None),
    feed_file: UploadFile = File(None),
    problem_type: str = Form(...),
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞
    
    problem_type –º–æ–∂–µ—Ç –±—ã—Ç—å:
    - MISSING_ID
    - MISSING_AVAILABLE
    - MISSING_NAME
    - MISSING_LINK
    - PRICE_ISSUES
    - MISSING_CATEGORY
    - INVALID_CATEGORY
    - MULTIPLE_CATEGORIES
    - MISSING_VENDOR
    - MISSING_IMAGE
    """
    try:
        if not feed_url and not feed_file:
            raise HTTPException(
                status_code=400,
                detail="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ª–∏–±–æ URL —Ñ–∏–¥–∞, –ª–∏–±–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª",
            )
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –≤ enum
        try:
            problem_enum = ProblemType[problem_type]
        except KeyError:
            raise HTTPException(
                status_code=400,
                detail=f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –ø—Ä–æ–±–ª–µ–º—ã: {problem_type}",
            )
        
        if feed_url:
            checker = FeedChecker(site_id=site_id, site_url=feed_url)
        else:
            file_content = await feed_file.read()
            checker = FeedChecker(site_id=site_id, file_content=file_content)
        
        # –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏
        checker.get_tree_object()
        checker.get_mandatory_requirements()
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
        problematic_offers = checker.get_problematic_offers(problem_enum)
        
        return JSONResponse(content={
            "problem_type": problem_type,
            "count": len(problematic_offers),
            "offers": problematic_offers,
        })
        
    except Exception as e:
        logger.error(f"Error getting problematic offers: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/export-excel")
async def export_excel(
    site_id: int = Form(...),
    feed_url: str = Form(None),
    feed_file: UploadFile = File(None),
):
    """
    –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ Excel —Ñ–∞–π–ª
    """
    try:
        if not feed_url and not feed_file:
            raise HTTPException(
                status_code=400,
                detail="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ª–∏–±–æ URL —Ñ–∏–¥–∞, –ª–∏–±–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª",
            )
        
        if feed_url:
            checker = FeedChecker(site_id=site_id, site_url=feed_url)
        else:
            file_content = await feed_file.read()
            checker = FeedChecker(site_id=site_id, file_content=file_content)
        
        # –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        result = checker.run_full_check()
        result["site_id"] = site_id
        
        # –°–æ–∑–¥–∞–Ω–∏–µ Excel —Ñ–∞–π–ª–∞
        excel_path = create_excel_report(result, site_id)
        
        # –í–æ–∑–≤—Ä–∞—Ç —Ñ–∞–π–ª–∞
        return FileResponse(
            path=excel_path,
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            filename=os.path.basename(excel_path),
        )
        
    except Exception as e:
        logger.error(f"Error exporting to Excel: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

