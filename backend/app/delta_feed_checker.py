"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–æ–≤ (CSV —Ñ–æ—Ä–º–∞—Ç)
–î–µ–ª—å—Ç–∞-—Ñ–∏–¥—ã —Å–æ–¥–µ—Ä–∂–∞—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–≤–∞—Ä–∞—Ö —Å –∏–∑–º–µ–Ω–µ–Ω–Ω–æ–π —Ü–µ–Ω–æ–π –∏–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å—é
"""
import csv
import io
import logging
import requests
from collections import Counter, defaultdict
from typing import Dict, List, Optional, Any
from enum import Enum

from app.exceptions import FeedDownloadError, FeedValidationError

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ –≤ main.py, –ø—Ä–æ—Å—Ç–æ –ø–æ–ª—É—á–∞–µ–º logger
logger = logging.getLogger(__name__)


class DeltaProblemType(Enum):
    """–¢–∏–ø—ã –ø—Ä–æ–±–ª–µ–º –≤ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞—Ö"""
    MISSING_ID = "–±–µ–∑ ID –∏–ª–∏ —Å –ø—É—Å—Ç—ã–º ID"
    MISSING_PRICE = "–±–µ–∑ —Ü–µ–Ω—ã –∏–ª–∏ —Å –ø—É—Å—Ç–æ–π —Ü–µ–Ω–æ–π"
    INVALID_PRICE = "—Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ü–µ–Ω–æ–π (–Ω–æ–ª—å, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è, –Ω–µ —á–∏—Å–ª–æ)"
    MISSING_AVAILABLE = "–±–µ–∑ —Ñ–ª–∞–≥–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏"
    DUPLICATE_ID = "–¥—É–±–ª–∏–∫–∞—Ç—ã ID"


class DeltaFeedChecker:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–æ–≤
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - –î–µ–ª—å—Ç–∞-—Ñ–∏–¥—ã —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –∏ –±–µ–∑
    - –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ;)
    - –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è: id, price, available
    - –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–ª—è: oldPrice, regionExternalId, –∞—Ç—Ä–∏–±—É—Ç—ã
    """
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–º–µ–Ω–∞ –ø–æ–ª–µ–π (—Ä–µ–≥–∏—Å—Ç—Ä –≤–∞–∂–µ–Ω –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤)
    REQUIRED_FIELDS = ['id', 'price', 'available']
    OPTIONAL_FIELDS = ['oldPrice', 'regionExternalId']
    
    def __init__(
        self,
        site_id: int,
        file_content: bytes = None,
        site_url: str = None,
        delimiter: str = ';',
        available_true_values: List[str] = None,
        attribute_delimiter: str = ',',
        filename: str = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DeltaFeedChecker
        
        Args:
            site_id: ID —Å–∞–π—Ç–∞
            file_content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –≤ –±–∞–π—Ç–∞—Ö
            site_url: URL —Ñ–∏–¥–∞ (–ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
            delimiter: –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å CSV (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ;)
            available_true_values: –ó–Ω–∞—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Å—á–∏—Ç–∞—é—Ç—Å—è "–≤ –Ω–∞–ª–∏—á–∏–∏" (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ['1', 'true', 'True', 'TRUE'])
            attribute_delimiter: –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∞—Ç—Ä–∏–±—É—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ,)
        """
        self.site_id = site_id
        self.file_content = file_content
        self.site_url = site_url
        self.delimiter = delimiter
        self.attribute_delimiter = attribute_delimiter
        self.filename = filename
        
        # Headers –¥–ª—è HTTP –∑–∞–ø—Ä–æ—Å–æ–≤
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/csv, application/csv, */*; q=0.01',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0',
        }
        
        # –ó–Ω–∞—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Å—á–∏—Ç–∞—é—Ç—Å—è "–≤ –Ω–∞–ª–∏—á–∏–∏"
        if available_true_values is None:
            self.available_true_values = ['1', 'true', 'True', 'TRUE']
        else:
            self.available_true_values = available_true_values
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞
        self.rows = []
        self.csv_headers = []  # –ó–∞–≥–æ–ª–æ–≤–∫–∏ CSV —Ñ–∞–π–ª–∞ (–Ω–µ –ø—É—Ç–∞—Ç—å —Å self.headers –¥–ª—è HTTP)
        self.has_headers = False
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_rows = 0
        self.available_count = 0
        self.unavailable_count = 0
        self.unique_ids = set()
        
        # –ü—Ä–æ–±–ª–µ–º—ã
        self.problems = {
            'missing_id': [],
            'missing_price': [],
            'invalid_price': [],
            'missing_available': [],
            'duplicate_ids': []
        }
        
        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
        self.rows_with_oldprice = 0
        self.rows_with_region = 0
        self.rows_with_attributes = 0
        self.attribute_names = set()
        
        # –î–µ—Ç–∞–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        self.duplicate_ids_details = []
        
        # –û—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
        self.parse_errors = []
    
    def _validate_file_format(self, content: str, response_headers: dict = None) -> None:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ —Ñ–∞–π–ª–∞ - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å CSV
        
        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
            response_headers: HTTP –∑–∞–≥–æ–ª–æ–≤–∫–∏ –æ—Ç–≤–µ—Ç–∞ (–µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø–æ URL)
        
        Raises:
            FeedValidationError: –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –Ω–µ CSV
        """
        # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ response_headers
        if response_headers is not None and not isinstance(response_headers, dict):
            logger.warning(f"‚ö†Ô∏è response_headers –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º, —Ç–∏–ø: {type(response_headers)}, –∑–Ω–∞—á–µ–Ω–∏–µ: {response_headers}")
            response_headers = {}
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –≤ URL
        if self.site_url:
            url_lower = self.site_url.lower()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –≤ URL - –µ—Å–ª–∏ —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω –Ω–µ-CSV —Ñ–æ—Ä–º–∞—Ç, –≤—ã–¥–∞–µ–º –æ—à–∏–±–∫—É
            non_csv_extensions = ['.xml', '.json', '.html', '.htm', '.xls', '.xlsx', '.txt']
            url_has_non_csv_ext = any(url_lower.endswith(ext) or f'{ext}?' in url_lower for ext in non_csv_extensions)
            
            if url_has_non_csv_ext:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–æ–π —Ñ–æ—Ä–º–∞—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω
                detected_ext = next((ext for ext in non_csv_extensions if url_lower.endswith(ext) or f'{ext}?' in url_lower), '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π')
                raise FeedValidationError(
                    message="–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞",
                    validation_results={
                        "format_error": True,
                        "error_message": f"URL —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Ñ–∞–π–ª —Ñ–æ—Ä–º–∞—Ç–∞ {detected_ext.upper()}, –æ–∂–∏–¥–∞–µ—Ç—Å—è CSV —Ñ–æ—Ä–º–∞—Ç",
                        "url": self.site_url,
                        "detected_format": detected_ext.upper().replace('.', '')
                    }
                )
            
            # –ï—Å–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –Ω–µ .csv, –ø—Ä–æ–≤–µ—Ä—è–µ–º Content-Type –∑–∞–≥–æ–ª–æ–≤–æ–∫
            if not (url_lower.endswith('.csv') or '.csv?' in url_lower):
                if response_headers and isinstance(response_headers, dict):
                    content_type = response_headers.get('Content-Type', '').lower()
                    if content_type and 'csv' not in content_type and 'text/plain' not in content_type:
                        # –ï—Å–ª–∏ Content-Type —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç
                        if 'xml' in content_type or 'json' in content_type or 'html' in content_type:
                            raise FeedValidationError(
                                message="–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞",
                                validation_results={
                                    "format_error": True,
                                    "error_message": f"–û–∂–∏–¥–∞–µ—Ç—Å—è CSV —Ñ–∞–π–ª, –ø–æ–ª—É—á–µ–Ω {content_type}",
                                    "url": self.site_url
                                }
                            )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª)
        if self.filename:
            filename_lower = self.filename.lower()
            if not filename_lower.endswith('.csv'):
                raise FeedValidationError(
                    message="–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞",
                    validation_results={
                        "format_error": True,
                        "error_message": f"–û–∂–∏–¥–∞–µ—Ç—Å—è CSV —Ñ–∞–π–ª, –ø–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º {filename_lower.split('.')[-1] if '.' in filename_lower else '–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è'}",
                        "filename": self.filename
                    }
                )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—á–∞–ª–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –Ω–∞ —è–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
        content_start = content.strip()[:200].lower()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ XML
        if content_start.startswith('<?xml') or content_start.startswith('<'):
            raise FeedValidationError(
                message="–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞",
                validation_results={
                    "format_error": True,
                    "error_message": "–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç XML —Ä–∞–∑–º–µ—Ç–∫—É, –æ–∂–∏–¥–∞–µ—Ç—Å—è CSV —Ñ–æ—Ä–º–∞—Ç",
                    "detected_format": "XML"
                }
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ JSON
        if content_start.startswith('{') or content_start.startswith('['):
            try:
                import json
                json.loads(content[:1000])  # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ JSON
                raise FeedValidationError(
                    message="–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞",
                    validation_results={
                        "format_error": True,
                        "error_message": "–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç JSON –¥–∞–Ω–Ω—ã–µ, –æ–∂–∏–¥–∞–µ—Ç—Å—è CSV —Ñ–æ—Ä–º–∞—Ç",
                        "detected_format": "JSON"
                    }
                )
            except (json.JSONDecodeError, ValueError):
                pass  # –ù–µ JSON, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
    
    def _get_file_content(self) -> str:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏
        
        Returns:
            –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –≤ UTF-8
        """
        try:
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ self.headers —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
            if not hasattr(self, 'headers') or not isinstance(self.headers, dict):
                logger.warning(f"‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: self.headers –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º –≤ –Ω–∞—á–∞–ª–µ _get_file_content! –¢–∏–ø: {type(getattr(self, 'headers', None))}")
                self.headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': 'text/csv, application/csv, */*; q=0.01',
                    'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1',
                    'Sec-Fetch-Dest': 'document',
                    'Sec-Fetch-Mode': 'navigate',
                    'Sec-Fetch-Site': 'none',
                    'Cache-Control': 'max-age=0',
                }
                logger.info(f"‚úÖ self.headers –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –Ω–∞—á–∞–ª–µ _get_file_content")
            
            if self.file_content:
                try:
                    # –ü—Ä–æ–±—É–µ–º UTF-8
                    content = self.file_content.decode('utf-8')
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ content —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞, –∞ –Ω–µ —Å–ø–∏—Å–æ–∫
                    if not isinstance(content, str):
                        logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ù–û: content –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å—Ç—Ä–æ–∫–æ–π! –¢–∏–ø: {type(content)}, –∑–Ω–∞—á–µ–Ω–∏–µ: {content}")
                        raise ValueError(f"content –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π, –ø–æ–ª—É—á–µ–Ω {type(content)}")
                    
                    self._validate_file_format(content)
                    
                    return content
                except UnicodeDecodeError:
                    # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                    try:
                        content = self.file_content.decode('cp1251')
                        logger.warning("–§–∞–π–ª –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω –∫–∞–∫ CP1251, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è UTF-8")
                        return content
                    except UnicodeDecodeError:
                        raise FeedValidationError(
                            message="–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª. –¢—Ä–µ–±—É–µ—Ç—Å—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞ UTF-8",
                            validation_results={}
                        )
            elif self.site_url:
                # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ URL
                try:
                    logger.info(f"üåê –ó–∞–≥—Ä—É–∑–∫–∞ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞ –ø–æ URL: {self.site_url}")
                    
                    # –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º self.headers –ü–ï–†–ï–î –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
                    logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ self.headers: —Ç–∏–ø={type(self.headers)}, –∑–Ω–∞—á–µ–Ω–∏–µ={self.headers}")
                    if not isinstance(self.headers, dict):
                        logger.warning(f"‚ö†Ô∏è self.headers –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º, —Ç–∏–ø: {type(self.headers)}, –ø–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º...")
                        self.headers = {
                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                            'Accept': 'text/csv, application/csv, */*; q=0.01',
                            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
                            'Accept-Encoding': 'gzip, deflate, br',
                            'Connection': 'keep-alive',
                            'Upgrade-Insecure-Requests': '1',
                            'Sec-Fetch-Dest': 'document',
                            'Sec-Fetch-Mode': 'navigate',
                            'Sec-Fetch-Site': 'none',
                            'Cache-Control': 'max-age=0',
                        }
                        logger.info(f"‚úÖ self.headers –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: —Ç–∏–ø={type(self.headers)}")
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º Referer –∑–∞–≥–æ–ª–æ–≤–æ–∫, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —Ç–æ—Ç –∂–µ –¥–æ–º–µ–Ω
                    from urllib.parse import urlparse
                    parsed_url = urlparse(self.site_url)
                    referer_url = f"{parsed_url.scheme}://{parsed_url.netloc}/"
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–æ–π
                    if not isinstance(self.headers, dict):
                        raise ValueError(f"self.headers –≤—Å–µ –µ—â–µ –Ω–µ —Å–ª–æ–≤–∞—Ä—å –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏! –¢–∏–ø: {type(self.headers)}")
                    
                    request_headers = {**self.headers, 'Referer': referer_url}
                    logger.info(f"üìã –ò—Å–ø–æ–ª—å–∑—É–µ–º Referer: {referer_url}")
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–æ–¥ –∑–∞–ø—Ä–æ—Å–∞
                    # –î–ª—è PHP —Ñ–∞–π–ª–æ–≤ —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º GET, –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è - POST
                    url_request = None
                    if self.site_url[-3:].lower() == 'php':
                        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º GET
                        try:
                            logger.info(f"üì° –ü—Ä–æ–±—É–µ–º GET –∑–∞–ø—Ä–æ—Å –¥–ª—è PHP —Ñ–∞–π–ª–∞...")
                            url_request = requests.get(self.site_url, headers=request_headers, timeout=300, allow_redirects=True)
                            url_request.raise_for_status()
                            logger.info(f"‚úÖ GET –∑–∞–ø—Ä–æ—Å —É—Å–ø–µ—à–µ–Ω: status={url_request.status_code}")
                        except requests.exceptions.HTTPError as e:
                            if e.response and e.response.status_code == 405:
                                # –ï—Å–ª–∏ GET –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω, –ø—Ä–æ–±—É–µ–º POST
                                logger.info(f"‚ö†Ô∏è GET –≤–µ—Ä–Ω—É–ª 405, –ø—Ä–æ–±—É–µ–º POST...")
                                url_request = requests.post(self.site_url, headers=request_headers, timeout=300, allow_redirects=True)
                                url_request.raise_for_status()
                                logger.info(f"‚úÖ POST –∑–∞–ø—Ä–æ—Å —É—Å–ø–µ—à–µ–Ω: status={url_request.status_code}")
                            else:
                                raise
                    else:
                        # –î–ª—è –Ω–µ-PHP —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º GET
                        logger.info(f"üì° –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ GET –∑–∞–ø—Ä–æ—Å–∞...")
                        url_request = requests.get(self.site_url, headers=request_headers, timeout=300, allow_redirects=True)
                        url_request.raise_for_status()
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º headers –≤ —Å–ª–æ–≤–∞—Ä—å –±–µ–∑–æ–ø–∞—Å–Ω–æ
                    headers_dict = {}
                    if url_request.headers:
                        try:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø headers –ø–µ—Ä–µ–¥ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º
                            if isinstance(url_request.headers, dict):
                                headers_dict = dict(url_request.headers)
                            elif hasattr(url_request.headers, 'items'):
                                headers_dict = dict(url_request.headers.items())
                            elif isinstance(url_request.headers, (list, tuple)):
                                # –ï—Å–ª–∏ headers —ç—Ç–æ —Å–ø–∏—Å–æ–∫, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
                                logger.warning(f"‚ö†Ô∏è headers —è–≤–ª—è–µ—Ç—Å—è —Å–ø–∏—Å–∫–æ–º, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º: {url_request.headers}")
                                headers_dict = {}
                            else:
                                # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Å–ª–æ–≤–∞—Ä—å
                                headers_dict = dict(url_request.headers)
                        except (TypeError, ValueError, AttributeError) as e:
                            # –ï—Å–ª–∏ headers –Ω–µ —Å–ª–æ–≤–∞—Ä—å, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
                            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å headers –≤ —Å–ª–æ–≤–∞—Ä—å: {e}, —Ç–∏–ø: {type(url_request.headers)}")
                            headers_dict = {}
                    
                    logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç: status={url_request.status_code}, headers={headers_dict}")
                    logger.info(f"üîç –¢–∏–ø headers_dict: {type(headers_dict)}, isinstance dict: {isinstance(headers_dict, dict)}")
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
                    content_bytes = url_request.content
                    content_preview = content_bytes[:1000].decode('utf-8', errors='ignore')
                    
                    if 'UTF-8' in content_preview or 'utf-8' in content_preview:
                        encoding = 'utf-8'
                        content = content_bytes.decode('utf-8', errors='replace')
                    elif 'windows-1251' in content_preview:
                        encoding = 'cp1251'
                        content = content_bytes.decode('cp1251', errors='replace')
                    else:
                        encoding = 'utf-8'
                        content = content_bytes.decode('utf-8', errors='replace')
                    
                    logger.info(f"üìÑ –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–æ —Å {encoding}, –¥–ª–∏–Ω–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–π headers_dict
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ headers_dict —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
                    if not isinstance(headers_dict, dict):
                        logger.warning(f"‚ö†Ô∏è headers_dict –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º –ø–µ—Ä–µ–¥ _validate_file_format, —Ç–∏–ø: {type(headers_dict)}, –∑–Ω–∞—á–µ–Ω–∏–µ: {headers_dict}")
                        headers_dict = {}
                    
                    logger.info(f"üîç –ü–µ—Ä–µ–¥ _validate_file_format, headers_dict —Ç–∏–ø: {type(headers_dict)}")
                    self._validate_file_format(content, headers_dict)
                    
                    return content
                    
                except requests.exceptions.ConnectionError as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ {self.site_url}: {e}")
                    raise FeedDownloadError(
                        message=f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ URL: {self.site_url}",
                        error_code="CONNECTION_ERROR",
                        url=self.site_url,
                        details={
                            "error_type": "ConnectionError",
                            "technical_message": str(e),
                            "suggestion": "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –∞–¥—Ä–µ—Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∏ —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω"
                        }
                    )
                except requests.exceptions.Timeout as e:
                    logger.error(f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {self.site_url}: {e}")
                    raise FeedDownloadError(
                        message=f"–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∏–¥–∞ (300 —Å–µ–∫—É–Ω–¥)",
                        error_code="TIMEOUT_ERROR",
                        url=self.site_url,
                        details={
                            "error_type": "Timeout",
                            "timeout_seconds": 300,
                            "technical_message": str(e),
                            "suggestion": "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–∫–æ—Ä–æ—Å—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"
                        }
                    )
                except requests.exceptions.HTTPError as e:
                    status_code = e.response.status_code if e.response else 0
                    logger.error(f"HTTP –æ—à–∏–±–∫–∞ {status_code} –¥–ª—è {self.site_url}: {e}")
                    
                    error_messages = {
                        404: ("–î–µ–ª—å—Ç–∞-—Ñ–∏–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω (404)", "NOT_FOUND", "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å URL"),
                        403: ("–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω (403)", "FORBIDDEN", "–í–æ–∑–º–æ–∂–Ω–æ, —Å–µ—Ä–≤–µ—Ä –±–ª–æ–∫–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å—ã"),
                        401: ("–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è (401)", "UNAUTHORIZED", "–ù–µ–æ–±—Ö–æ–¥–∏–º–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∏–¥—É"),
                        500: ("–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ (500)", "SERVER_ERROR", "–ü—Ä–æ–±–ª–µ–º–∞ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ —Å–µ—Ä–≤–µ—Ä–∞"),
                        502: ("Bad Gateway (502)", "BAD_GATEWAY", "–°–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"),
                        503: ("Service Unavailable (503)", "SERVICE_UNAVAILABLE", "–°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"),
                    }
                    
                    if status_code in error_messages:
                        msg, code, suggestion = error_messages[status_code]
                    else:
                        msg = f"–û—à–∏–±–∫–∞ HTTP {status_code}" if status_code > 0 else "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞"
                        code = f"HTTP_{status_code}" if status_code > 0 else "HTTP_ERROR"
                        suggestion = "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ URL –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞"
                    
                    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º headers –≤ —Å–ª–æ–≤–∞—Ä—å
                    response_headers = {}
                    if e.response and e.response.headers:
                        try:
                            if isinstance(e.response.headers, dict):
                                response_headers = dict(e.response.headers)
                            elif hasattr(e.response.headers, 'items'):
                                response_headers = dict(e.response.headers.items())
                            else:
                                response_headers = {}
                        except (TypeError, ValueError, AttributeError):
                            response_headers = {}
                    
                    raise FeedDownloadError(
                        message=msg,
                        error_code=code,
                        url=self.site_url,
                        status_code=status_code if status_code > 0 else None,
                        details={
                            "error_type": "HTTPError",
                            "technical_message": str(e),
                            "suggestion": suggestion,
                            "response_headers": response_headers
                        }
                    )
                except requests.exceptions.RequestException as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ {self.site_url}: {e}")
                    logger.error(f"–¢–∏–ø –∏—Å–∫–ª—é—á–µ–Ω–∏—è: {type(e).__name__}")
                    logger.error(f"–î–µ—Ç–∞–ª–∏: {str(e)}")
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∏–ø –æ—à–∏–±–∫–∏
                    error_code = "REQUEST_ERROR"
                    error_message = "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞"
                    
                    if isinstance(e, requests.exceptions.SSLError):
                        error_code = "SSL_ERROR"
                        error_message = "–û—à–∏–±–∫–∞ SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞"
                    elif isinstance(e, requests.exceptions.InvalidURL):
                        error_code = "INVALID_URL"
                        error_message = "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞"
                    
                    raise FeedDownloadError(
                        message=error_message,
                        error_code=error_code,
                        url=self.site_url,
                        details={
                            "error_type": type(e).__name__,
                            "technical_message": str(e),
                            "suggestion": "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ URL –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞"
                        }
                    )
                except Exception as e:
                    # –ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
                    logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞ {self.site_url}: {e}")
                    logger.error(f"–¢–∏–ø –∏—Å–∫–ª—é—á–µ–Ω–∏—è: {type(e).__name__}")
                    import traceback
                    logger.error(f"Traceback: {traceback.format_exc()}")
                    
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ details —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
                    error_details = {
                        "error_type": type(e).__name__,
                        "technical_message": str(e),
                        "suggestion": "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ URL –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞. –ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
                    }
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
                    if not isinstance(error_details, dict):
                        logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ù–û: error_details –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º! –¢–∏–ø: {type(error_details)}")
                        error_details = {"error": str(e)}
                    
                    raise FeedDownloadError(
                        message=f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞: {str(e)}",
                        error_code="UNKNOWN_ERROR",
                        url=self.site_url,
                        details=error_details
                    )
        except Exception as outer_e:
            # –ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º –ª—é–±—ã–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –ø—Ä–æ–∏–∑–æ–π—Ç–∏ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—à–∏–±–æ–∫
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—à–∏–±–∫–∏ –≤ _get_file_content: {outer_e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –æ—à–∏–±–∫—É, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –Ω–∞—à–∞ –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            if isinstance(outer_e, (FeedDownloadError, FeedValidationError)):
                raise
            # –ò–Ω–∞—á–µ —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –æ—à–∏–±–∫—É
            raise FeedDownloadError(
                message=f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞: {str(outer_e)}",
                error_code="CRITICAL_ERROR",
                url=getattr(self, 'site_url', None),
                details={"error": str(outer_e)}
            )
        else:
            raise FeedValidationError(
                message="–ù–µ —É–∫–∞–∑–∞–Ω –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö (file_content –∏–ª–∏ site_url)",
                validation_results={}
            )
    
    def _detect_headers(self, first_line: str) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ
        
        Args:
            first_line: –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ —Ñ–∞–π–ª–∞
            
        Returns:
            True –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏, False –µ—Å–ª–∏ –Ω–µ—Ç
        """
        parts = first_line.split(self.delimiter)
        parts = [p.strip() for p in parts]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ö–æ–∂–∏ –ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç –±—É–∫–≤—ã –∏ –Ω–µ –ø–æ—Ö–æ–∂–∏ –Ω–∞ —á–∏—Å–ª–∞
        header_indicators = ['id', 'price', 'available', 'oldprice', 'region', '–Ω–∞–ª–∏—á–∏–µ', '—Ü–≤–µ—Ç']
        
        first_part_lower = parts[0].lower() if parts else ''
        
        # –ï—Å–ª–∏ –ø–µ—Ä–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ –ø–æ—Ö–æ–∂–∞ –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–æ–∫
        if any(indicator in first_part_lower for indicator in header_indicators):
            return True
        
        # –ï—Å–ª–∏ –≤—Å–µ —á–∞—Å—Ç–∏ –ø–æ—Ö–æ–∂–∏ –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∏ (—Å–æ–¥–µ—Ä–∂–∞—Ç –±—É–∫–≤—ã, –Ω–µ —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã)
        if len(parts) >= 3:
            non_numeric_count = sum(1 for p in parts if not p.replace('.', '').replace('-', '').isdigit())
            if non_numeric_count >= 2:  # –•–æ—Ç—è –±—ã 2 –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ —á–∏—Å–ª–æ–≤—ã–µ
                return True
        
        return False
    
    def _parse_row(self, row_data: List[str], row_number: int, field_mapping: Dict[int, str] = None) -> Dict[str, Any]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–æ–∫–∏ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞
        
        Args:
            row_data: –°–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ CSV —Å—Ç—Ä–æ–∫–∏
            row_number: –ù–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ (–¥–ª—è –æ—Ç—á–µ—Ç–æ–≤)
            field_mapping: –ú–∞–ø–ø–∏–Ω–≥ –∏–Ω–¥–µ–∫—Å–æ–≤ –∫–æ–ª–æ–Ω–æ–∫ –Ω–∞ –∏–º–µ–Ω–∞ –ø–æ–ª–µ–π (–µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        """
        parsed = {
            'row_number': row_number,
            'id': None,
            'price': None,
            'available': None,
            'oldPrice': None,
            'regionExternalId': None,
            'attributes': {},
            'raw_data': row_data
        }
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –º–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π (–∑–∞–≥–æ–ª–æ–≤–∫–∏)
        if field_mapping:
            for col_index, field_name in field_mapping.items():
                if col_index < len(row_data):
                    value = row_data[col_index].strip()
                    
                    # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                    if field_name.lower() == 'id':
                        parsed['id'] = value
                    elif field_name.lower() == 'price':
                        parsed['price'] = value
                    elif field_name.lower() == 'available':
                        parsed['available'] = value
                    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
                    elif field_name == 'oldPrice':
                        parsed['oldPrice'] = value if value else None
                    elif field_name == 'regionExternalId':
                        parsed['regionExternalId'] = value if value else None
                    # –ê—Ç—Ä–∏–±—É—Ç—ã (–≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è)
                    else:
                        if value:
                            parsed['attributes'][field_name] = value
                            self.attribute_names.add(field_name)
        else:
            # –ù–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            # –§–æ—Ä–º–∞—Ç: id, price, available [, regionExternalId] [, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è]
            if len(row_data) >= 3:
                parsed['id'] = row_data[0].strip()
                parsed['price'] = row_data[1].strip()
                parsed['available'] = row_data[2].strip()
                
                # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π regionExternalId –≤ 4-–π –ø–æ–∑–∏—Ü–∏–∏
                if len(row_data) >= 4:
                    region_value = row_data[3].strip()
                    if region_value:
                        parsed['regionExternalId'] = region_value
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è (5-—è –ø–æ–∑–∏—Ü–∏—è –∏ –¥–∞–ª–µ–µ) —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –∞—Ç—Ä–∏–±—É—Ç—ã
                if len(row_data) >= 5:
                    for idx in range(4, len(row_data)):
                        attr_name = f"field_{idx + 1}"
                        attr_value = row_data[idx].strip()
                        if attr_value:
                            parsed['attributes'][attr_name] = attr_value
                            self.attribute_names.add(attr_name)
        
        return parsed
    
    def _validate_row(self, row: Dict[str, Any]) -> List[str]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä–æ–∫–∏ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞
        
        Args:
            row: –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–∏–ø–æ–≤ –ø—Ä–æ–±–ª–µ–º (–ø—É—Å—Ç–æ–π –µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º –Ω–µ—Ç)
        """
        problems = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ ID
        if not row['id'] or not row['id'].strip():
            problems.append('missing_id')
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–Ω—ã
        if not row['price'] or not row['price'].strip():
            problems.append('missing_price')
        else:
            try:
                price_value = float(row['price'].replace(',', '.'))
                if price_value <= 0:
                    problems.append('invalid_price')
            except (ValueError, AttributeError):
                problems.append('invalid_price')
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ available
        if row['available'] is None or not str(row['available']).strip():
            problems.append('missing_available')
        
        return problems
    
    def _is_available(self, available_value: str) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Ç–æ–≤–∞—Ä–∞
        
        Args:
            available_value: –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ–ª—è available
            
        Returns:
            True –µ—Å–ª–∏ —Ç–æ–≤–∞—Ä –≤ –Ω–∞–ª–∏—á–∏–∏, False –µ—Å–ª–∏ –Ω–µ—Ç
        """
        if available_value is None:
            return False
        
        available_str = str(available_value).strip()
        return available_str in self.available_true_values
    
    def parse(self) -> Dict[str, Any]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
        """
        try:
            content = self._get_file_content()
            if not content or not content.strip():
                raise FeedValidationError(
                    message="–§–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
                    validation_results={
                        "parsing_error": True,
                        "error_message": "–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
                    }
                )
            
            lines = content.strip().split('\n')
            
            if not lines:
                raise FeedValidationError(
                    message="–§–∞–π–ª –ø—É—Å—Ç",
                    validation_results={
                        "parsing_error": True,
                        "error_message": "–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç—Ä–æ–∫"
                    }
                )
        except FeedValidationError:
            raise
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise FeedValidationError(
                message=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}",
                validation_results={
                    "parsing_error": True,
                    "error_message": str(e),
                    "error_type": type(e).__name__
                }
            )
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        first_line = lines[0].strip()
        self.has_headers = self._detect_headers(first_line)
        
        # –ü–∞—Ä—Å–∏–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        field_mapping = {}  # –ò–Ω–¥–µ–∫—Å –∫–æ–ª–æ–Ω–∫–∏ -> –∏–º—è –ø–æ–ª—è
        if self.has_headers:
            header_parts = first_line.split(self.delimiter)
            for idx, header in enumerate(header_parts):
                field_mapping[idx] = header.strip()
            self.csv_headers = [h.strip() for h in header_parts]
            logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∑–∞–≥–æ–ª–æ–≤–∫–∏: {self.csv_headers}")
            start_row = 1  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        else:
            logger.info("–ó–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç")
            start_row = 0
        
        # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        id_counter = Counter()
        parse_errors = []
        
        for line_idx, line in enumerate(lines[start_row:], start=start_row + 1):
            line = line.strip()
            if not line:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                continue
            
            # –ü–∞—Ä—Å–∏–º CSV —Å—Ç—Ä–æ–∫—É
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º csv.reader –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–≤—ã—á–µ–∫
                csv_reader = csv.reader([line], delimiter=self.delimiter)
                row_data = next(csv_reader)
            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ {line_idx}: {e}. –°—Ç—Ä–æ–∫–∞: {line[:100]}"
                logger.warning(error_msg)
                parse_errors.append({
                    "line": line_idx,
                    "error": str(e),
                    "content": line[:100]
                })
                continue
            
            # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫—É
            parsed_row = self._parse_row(row_data, line_idx, field_mapping if self.has_headers else None)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            problems = self._validate_row(parsed_row)
            for problem in problems:
                self.problems[problem].append(parsed_row)
            
            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            if parsed_row['id']:
                id_counter[parsed_row['id']] += 1
                self.unique_ids.add(parsed_row['id'])
            
            # –ü–æ–¥—Å—á–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
            if parsed_row['available']:
                if self._is_available(parsed_row['available']):
                    self.available_count += 1
                else:
                    self.unavailable_count += 1
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
            if parsed_row.get('oldPrice'):
                self.rows_with_oldprice += 1
            
            if parsed_row.get('regionExternalId'):
                self.rows_with_region += 1
            
            if parsed_row.get('attributes'):
                self.rows_with_attributes += 1
            
            self.rows.append(parsed_row)
            self.total_rows += 1
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∏ –ª–∏ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω—ã —Ö–æ—Ç—è –±—ã –∫–∞–∫–∏–µ-—Ç–æ —Å—Ç—Ä–æ–∫–∏
        if self.total_rows == 0:
            error_msg = "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö"
            if parse_errors:
                error_msg += f". –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(parse_errors)} –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞."
            logger.error(error_msg)
            raise FeedValidationError(
                message=error_msg,
                validation_results={
                    "parsing_error": True,
                    "error_message": error_msg,
                    "parse_errors": parse_errors[:10] if parse_errors else [],
                    "total_lines": len(lines),
                    "has_headers": self.has_headers
                }
            )
        
        # –ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        for product_id, count in id_counter.items():
            if count > 1:
                duplicate_rows = [r for r in self.rows if r['id'] == product_id]
                self.duplicate_ids_details.append({
                    'id': product_id,
                    'count': count,
                    'rows': [
                        {
                            'row_number': r['row_number'],
                            'price': r['price'],
                            'available': r['available'],
                            'regionExternalId': r.get('regionExternalId')
                        }
                        for r in duplicate_rows
                    ]
                })
                self.problems['duplicate_ids'].extend(duplicate_rows)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
        if parse_errors:
            logger.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(parse_errors)} –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫")
            if len(parse_errors) <= 10:
                for err in parse_errors:
                    logger.warning(f"  –°—Ç—Ä–æ–∫–∞ {err['line']}: {err['error']}")
        
        result = {
            'total_rows': self.total_rows,
            'has_headers': self.has_headers,
            'headers': self.csv_headers if self.has_headers else None
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–∞—Ö –ø–∞—Ä—Å–∏–Ω–≥–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
        if parse_errors:
            result['parse_errors'] = parse_errors[:10]  # –ü–µ—Ä–≤—ã–µ 10 –æ—à–∏–±–æ–∫
            result['parse_errors_count'] = len(parse_errors)
        
        logger.info(f"–£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {self.total_rows} —Å—Ç—Ä–æ–∫ –∏–∑ {len(lines)} –≤—Å–µ–≥–æ —Å—Ç—Ä–æ–∫")
        
        return result
    
    def run_full_check(self) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
        """
        logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞ –¥–ª—è site_id={self.site_id}")
        
        try:
            # –ü–∞—Ä—Å–∏–Ω–≥
            parsing_result = self.parse()
        except FeedValidationError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞: {e.message}")
            logger.error(f"–î–µ—Ç–∞–ª–∏: {e.validation_results}")
            # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–∞–ª—å—à–µ, —á—Ç–æ–±—ã backend –º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
            raise
        except Exception as e:
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise FeedValidationError(
                message=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –¥–µ–ª—å—Ç–∞-—Ñ–∏–¥–∞: {str(e)}",
                validation_results={
                    "parsing_error": True,
                    "error_message": str(e),
                    "error_type": type(e).__name__
                }
            )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'site_id': self.site_id,
            'parsing': parsing_result,
            'summary': {
                'total_rows': self.total_rows,
                'available_count': self.available_count,
                'unavailable_count': self.unavailable_count,
                'unique_ids_count': len(self.unique_ids)
            },
            'problems': {
                'missing_id': len(self.problems['missing_id']),
                'missing_price': len(self.problems['missing_price']),
                'invalid_price': len(self.problems['invalid_price']),
                'missing_available': len(self.problems['missing_available']),
                'duplicate_ids': len(set(r['id'] for r in self.problems['duplicate_ids'] if r['id']))
            },
            'optional_fields': {
                'rows_with_oldprice': self.rows_with_oldprice,
                'rows_with_region': self.rows_with_region,
                'rows_with_attributes': self.rows_with_attributes,
                'attribute_names': sorted(list(self.attribute_names))
            },
            'duplicate_ids_details': self.duplicate_ids_details
        }
        
        logger.info(f"‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {self.total_rows} —Å—Ç—Ä–æ–∫, {len(self.unique_ids)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID")
        
        return result

